from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import pandas as pd
import time

def crawl_zighang(job_name="ì„œë²„Â·ë°±ì—”ë“œ", max_clicks=10):
    options = Options()
    options.add_argument("--headless")  # í•„ìš” ì‹œ ì œê±° ê°€ëŠ¥
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    driver = webdriver.Chrome(options=options)
    driver.set_window_size(1280, 1024)
    wait = WebDriverWait(driver, 20)

    try:
        driver.get("https://zighang.com/it")
        time.sleep(2)

        arrow_xpath = '//*[@id="root"]/main/div[3]/div/div/div/div/div[2]/div/section/button[2]/div/img'
        wait.until(EC.element_to_be_clickable((By.XPATH, arrow_xpath))).click()
        time.sleep(1)

        job_button_xpath = f'//button[normalize-space()="{job_name}"]'
        wait.until(EC.element_to_be_clickable((By.XPATH, job_button_xpath))).click()
        time.sleep(1)

        confirm_button = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div.sticky.bottom-0 button.bg-primary')))
        driver.execute_script("arguments[0].scrollIntoView(true);", confirm_button)
        driver.execute_script("arguments[0].click();", confirm_button)
        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'p.ds-web-title2')))

        original_tab = driver.current_window_handle
        results = []

        for i in range(2, max_clicks + 1):
            try:
                title_xpath = f'(//p[contains(@class, "ds-web-title2")])[{i}]'
                title_elem = wait.until(EC.presence_of_element_located((By.XPATH, title_xpath)))
                driver.execute_script("arguments[0].scrollIntoView(true);", title_elem)
                driver.execute_script("window.scrollBy(0, -200);")
                time.sleep(0.3)

                parent_link = title_elem.find_element(By.XPATH, "./ancestor::a[1]")
                driver.execute_script("arguments[0].click();", parent_link)
                time.sleep(2)

                new_tab = [tab for tab in driver.window_handles if tab != original_tab][0]
                driver.switch_to.window(new_tab)

                data = {}
                data["íšŒì‚¬ëª…"] = driver.find_element(By.XPATH, '//*[@id="root"]/main/div[2]/div[1]/div[1]/div[1]/div[1]/div/a').text
                data["ê²½ë ¥"] = driver.find_element(By.XPATH, '//*[@id="root"]/main/div[2]/div[1]/div[1]/div[1]/div[5]/div/section/div[1]/div/div').text
                data["í•™ë ¥"] = driver.find_element(By.XPATH, '//*[@id="root"]/main/div[2]/div[1]/div[1]/div[1]/div[5]/div/section/div[3]/div/div').text
                data["ê·¼ë¬´ì§€"] = driver.find_element(By.XPATH, '//*[@id="root"]/main/div[2]/div[1]/div[1]/div[1]/div[5]/div/section/div[2]/div/div').text
                data["ì§êµ°"] = job_name

                try:
                    data["ìš°ëŒ€ì‚¬í•­"] = driver.find_element(By.XPATH, '//h2[text()="ìš°ëŒ€ì‚¬í•­"]/following-sibling::p').text
                except:
                    data["ìš°ëŒ€ì‚¬í•­"] = ""

                try:
                    data["ìê²©ìš”ê±´"] = driver.find_element(By.XPATH, '//h2[text()="ìê²©ìš”ê±´"]/following-sibling::p').text
                except:
                    data["ìê²©ìš”ê±´"] = ""

                if data["ìš°ëŒ€ì‚¬í•­"] == "" and data["ìê²©ìš”ê±´"] == "":
                    try:
                        img_elem = driver.find_element(By.XPATH, '//*[@id="root"]/main/div[2]/div[1]/div[1]/div[4]/img')
                        data["ì´ë¯¸ì§€ê²½ë¡œ"] = img_elem.get_attribute("src")
                    except:
                        data["ì´ë¯¸ì§€ê²½ë¡œ"] = ""
                else:
                    data["ì´ë¯¸ì§€ê²½ë¡œ"] = ""

                results.append(data)
                driver.close()
                driver.switch_to.window(original_tab)

            except Exception as e:
                print(f"âŒ [{i}]ë²ˆì§¸ ê³µê³  ì‹¤íŒ¨: {e}")
                continue

        return pd.DataFrame(results)

    finally:
        driver.quit()




def crawl_linkareer(max_pages=5):
    chrome_options = Options()
    chrome_options.add_experimental_option("detach", True)
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    # chrome_options.add_argument("--headless")  # í•„ìš” ì‹œ ì£¼ì„ ì œê±°
    driver = webdriver.Chrome(options=chrome_options)
    wait = WebDriverWait(driver, 10)

    results = []

    try:
        for page in range(1, max_pages + 1):
            list_url = f"https://linkareer.com/list/recruit?filterBy_activityTypeID=5&filterBy_categoryIDs=58&filterBy_status=OPEN&orderBy_direction=DESC&orderBy_field=RECENT&page={page}"
            driver.get(list_url)
            time.sleep(2)
            print(f"ğŸ“„ {page}í˜ì´ì§€ ì ‘ì† ì™„ë£Œ")

            main_window = driver.current_window_handle
            row_count = len(driver.find_elements(By.XPATH, '//*[@id="__next"]/div[1]/div/main/div/section/div[2]/table/tbody/tr'))
            print(f"ğŸ” {row_count}ê°œì˜ ê³µê³  íƒìƒ‰ ì˜ˆì •")

            for i in range(1, row_count + 1):
                try:
                    link_element = driver.find_element(By.XPATH, f'//*[@id="__next"]/div[1]/div/main/div/section/div[2]/table/tbody/tr[{i}]/td[2]/div/a/div/p')
                    link_element.click()

                    driver.switch_to.window(driver.window_handles[-1])

                    company_name = wait.until(EC.presence_of_element_located(
                        (By.XPATH, '//*[@id="__next"]/div[1]/div/main/div/div/section[1]/div/article/header/h2'))).text.strip()
                    company_type = wait.until(EC.presence_of_element_located(
                        (By.XPATH, '//*[@id="__next"]/div[1]/div/main/div/div/section[1]/div/article/div/dl[1]/dd'))).text.strip()
                    position_element = wait.until(EC.presence_of_element_located(
                        (By.XPATH, '//*[@id="__next"]/div[1]/div/main/div/div/section[1]/div/article/div/dl[5]/dd')))
                    position = position_element.text.strip()

                    p_elements = driver.find_elements(By.XPATH, '//*[@id="DETAIL"]/section[1]/div/p')
                    p_texts = [p.text.strip() for p in p_elements]

                    qual_idx = next((idx for idx, text in enumerate(p_texts) if 'ìê²©ìš”ê±´' in text or 'ìê²© ìš”ê±´' in text), None)
                    pos_idx = next((idx for idx, text in enumerate(p_texts) if 'ëª¨ì§‘ ì§ë¬´' in text or 'ì„¸ë¶€ ì§ë¬´' in text), None)

                    qualification_texts = []
                    if qual_idx is not None:
                        for t in p_texts[qual_idx + 1:]:
                            if any(keyword in t for keyword in ['ì§€ì›', 'í˜œíƒ', 'ìš°ëŒ€', 'ë‹¤ìŒ', 'ê·¼ë¬´']):
                                break
                            qualification_texts.append(t)
                    qualification = "\n".join(qualification_texts)

                    detail_position = ''
                    if pos_idx is not None and pos_idx + 1 < len(p_texts):
                        detail_position = p_texts[pos_idx + 1]

                    results.append({
                        'íšŒì‚¬ëª…': company_name,
                        'ê¸°ì—…í˜•íƒœ': company_type,
                        'ëª¨ì§‘ì§ë¬´': position,
                        'ì„¸ë¶€ì§ë¬´': detail_position,
                        'ìê²©ìš”ê±´': qualification
                    })

                    print(f"âœ… {company_name} ({i}/{row_count}, page {page}) í¬ë¡¤ë§ ì™„ë£Œ")
                    driver.close()
                    driver.switch_to.window(main_window)
                    time.sleep(1)

                except Exception as e:
                    print(f"âŒ {page}í˜ì´ì§€ {i}ë²ˆì§¸ ê³µê³  ì˜¤ë¥˜: {e}")
                    if len(driver.window_handles) > 1:
                        driver.close()
                        driver.switch_to.window(main_window)
                    continue

        return pd.DataFrame(results)

    finally:
        driver.quit()