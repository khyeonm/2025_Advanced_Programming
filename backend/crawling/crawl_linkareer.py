from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time

import pandas as pd
import time


chrome_options = Options()
chrome_options.add_experimental_option("detach", True)
driver = webdriver.Chrome(options=chrome_options)
wait = WebDriverWait(driver, 10)

results = []

# í¬ë¡¤ë§í•  í˜ì´ì§€ ë²”ìœ„ (1~5í˜ì´ì§€ ì˜ˆì‹œ)
for page in range(1, 6):  # í•„ìš”ì‹œ 1~ì›í•˜ëŠ” í˜ì´ì§€ ë²”ìœ„ ìˆ˜ì •
    list_url = f"https://linkareer.com/list/recruit?filterBy_activityTypeID=5&filterBy_categoryIDs=58&filterBy_status=OPEN&orderBy_direction=DESC&orderBy_field=RECENT&page={page}"
    driver.get(list_url)
    time.sleep(2)

    print(f"ğŸ“„ {page}í˜ì´ì§€ ì ‘ì† ì™„ë£Œ")

    # ë©”ì¸ íƒ­ í•¸ë“¤ ì €ì¥
    main_window = driver.current_window_handle

    # ê³µê³  row ê°œìˆ˜ ê°€ì ¸ì˜¤ê¸°
    row_count = len(driver.find_elements(By.XPATH, '//*[@id="__next"]/div[1]/div/main/div/section/div[2]/table/tbody/tr'))
    print(f"{row_count}ê°œì˜ ê³µê³  íƒìƒ‰ ì˜ˆì •")

    for i in range(1, row_count + 1):
        try:
            link_element = driver.find_element(By.XPATH, f'//*[@id="__next"]/div[1]/div/main/div/section/div[2]/table/tbody/tr[{i}]/td[2]/div/a/div/p')
            link_element.click()

            # ìƒˆ íƒ­ìœ¼ë¡œ ì „í™˜
            driver.switch_to.window(driver.window_handles[-1])

            # ê¸°ë³¸ ì •ë³´ í¬ë¡¤ë§
            company_name = wait.until(EC.presence_of_element_located((By.XPATH, '//*[@id="__next"]/div[1]/div/main/div/div/section[1]/div/article/header/h2'))).text.strip()
            company_type = wait.until(EC.presence_of_element_located((By.XPATH, '//*[@id="__next"]/div[1]/div/main/div/div/section[1]/div/article/div/dl[1]/dd'))).text.strip()

            position_element = wait.until(EC.presence_of_element_located((By.XPATH, '//*[@id="__next"]/div[1]/div/main/div/div/section[1]/div/article/div/dl[5]/dd')))
            position = position_element.text.strip()

            # ëª¨ë“  p íƒœê·¸ í…ìŠ¤íŠ¸ ìˆ˜ì§‘
            p_elements = driver.find_elements(By.XPATH, '//*[@id="DETAIL"]/section[1]/div/p')
            p_texts = [p.text.strip() for p in p_elements]

            # ìê²©ìš”ê±´/ëª¨ì§‘ì§ë¬´ ì¸ë±ìŠ¤ íƒìƒ‰
            qual_idx = next((idx for idx, text in enumerate(p_texts) if 'ìê²©ìš”ê±´' in text or 'ìê²© ìš”ê±´' in text), None)
            pos_idx = next((idx for idx, text in enumerate(p_texts) if 'ëª¨ì§‘ ì§ë¬´' in text or 'ì„¸ë¶€ ì§ë¬´' in text), None)

            # ìê²©ìš”ê±´ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            qualification_texts = []
            if qual_idx is not None:
                for t in p_texts[qual_idx + 1:]:
                    if any(keyword in t for keyword in ['ì§€ì›', 'í˜œíƒ', 'ìš°ëŒ€', 'ë‹¤ìŒ', 'ê·¼ë¬´']):
                        break
                    qualification_texts.append(t)
            qualification = "\n".join(qualification_texts)

            # ì„¸ë¶€ì§ë¬´ ì¶”ì¶œ
            detail_position = ''
            if pos_idx is not None:
                detail_position = p_texts[pos_idx + 1] if pos_idx + 1 < len(p_texts) else ''

            # ê²°ê³¼ ì €ì¥
            results.append({
                'íšŒì‚¬ëª…': company_name,
                'ê¸°ì—…í˜•íƒœ': company_type,
                'ëª¨ì§‘ì§ë¬´': position,
                'ì„¸ë¶€ì§ë¬´': detail_position,
                'ìê²©ìš”ê±´': qualification
            })

            print(f"{company_name} ({i}/{row_count}, page {page}) í¬ë¡¤ë§ ì™„ë£Œ")

            # ìƒˆ íƒ­ ë‹«ê¸° & ë©”ì¸ íƒ­ìœ¼ë¡œ ì „í™˜
            driver.close()
            driver.switch_to.window(main_window)

            time.sleep(1)

        except Exception as e:
            print(f"{page}í˜ì´ì§€ {i}ë²ˆì§¸ ê³µê³  ì˜¤ë¥˜: {e}")
            # ì˜ˆì™¸ ì‹œ ìƒˆ íƒ­ ë‹«ê³  ë©”ì¸ íƒ­ ë³µê·€
            if len(driver.window_handles) > 1:
                driver.close()
                driver.switch_to.window(main_window)
            continue

driver.quit()

# DataFrame ë³€í™˜ ë° ì €ì¥
df = pd.DataFrame(results)
df.to_csv('linkareer_crawling.csv', index=False, encoding='utf-8-sig')

print("í¬ë¡¤ë§ ì™„ë£Œ! CSV ì €ì¥ë¨.")